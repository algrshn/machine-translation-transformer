# Coding a transformer model from scratch (as described in *Attention is All You Need* paper) and training it on WMT14 EN-DE dataset
This is a pure training exercise. I wanted to replicate the machine translation results from [*Attention is All You Need*](https://arxiv.org/pdf/1706.03762.pdf) paper and teach myself coding transformers.
