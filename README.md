# Coding a transformer model from scratch (as described in *Attention is All You Need* paper) and training it on WMT14 EN-DE dataset
This is a pure training exercise. I wanted to replicate machine translation results from *Attention is All You Need* paper and teach myself coding transformers.
